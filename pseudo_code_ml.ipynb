# Perform initian import of the needed libraries

# Read the CSV and perform basic data cleaning
    # Load the data, file_path = 
    # Drop the null columns where all values are null
    # Drop the null rows
    # Convert data in any other format than numerical to numerical
    # Define the target column
    # Show dataframe

# Preprocess data, split the data into Training and Testing
    # Create feature set X = 
    # Create target y =
    # Split into Train and Test sets. X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)
    # Create a StandardScaler instance. scaler = StandardScaler()
    # Fit the Standard Scaler with the training data. X_scaler = scaler.fit(X_train)
    # Scale the data. X_train_scaled = X_scaler.transform(X_train). X_test_scaled = X_scaler.transform(X_test)
    
    # Check the balance of our target values (?)
    # Determine the shape of our training and testing sets

# Perform ensemble learning algorythm, random forests


